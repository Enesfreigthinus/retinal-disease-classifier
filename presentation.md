# Retinal Disease Classifier - Sunum Slayt Rehberi

> **Not**: Bu dokÃ¼manda her slide iÃ§in gÃ¶sterilecek iÃ§erik, gÃ¶rsel Ã¶nerileri ve anlatÄ±m notlarÄ± yer almaktadÄ±r.

## ğŸ“‹ Ä°Ã§indekiler ve Slide PlanÄ±

**Toplam Ã–nerilen Slide SayÄ±sÄ±: 25-30 slide**

1. [BaÅŸlÄ±k ve TanÄ±tÄ±m](#slide-1-baÅŸlÄ±k-ve-tanÄ±tÄ±m) - 1 slide
2. [Problem TanÄ±mÄ± ve Motivasyon](#slide-2-3-problem-tanÄ±mÄ±) - 2 slide
3. [Veri Seti ve GÃ¶rselleÅŸtirme](#slide-4-8-veri-seti) - 5 slide
4. [Model Mimarisi: ConvNeXt](#slide-9-13-model-mimarisi) - 5 slide
5. [Transfer Learning ve Fine-Tuning](#slide-14-16-transfer-learning) - 3 slide
6. [Veri Ã–n Ä°ÅŸleme ve Augmentation](#slide-17-18-veri-hazÄ±rlama) - 2 slide
7. [SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler](#slide-19-21-sÄ±nÄ±f-dengesizliÄŸi) - 3 slide
8. [EÄŸitim Stratejisi ve Hiperparametreler](#slide-22-23-eÄŸitim) - 2 slide
9. [SonuÃ§lar ve Performans Analizi](#slide-24-28-sonuÃ§lar) - 5 slide
10. [Demo ve Ã–rnek Tahminler](#slide-29-demo) - 1 slide
11. [SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar](#slide-30-sonuÃ§) - 1 slide

---

## SLIDE 1: BaÅŸlÄ±k ve TanÄ±tÄ±m

### ğŸ“Š Slide Ä°Ã§eriÄŸi

**BaÅŸlÄ±k (BÃ¼yÃ¼k, OrtalanmÄ±ÅŸ)**:

```
Retinal Disease Classifier
Derin Ã–ÄŸrenme ile 16 FarklÄ± Retinal HastalÄ±ÄŸÄ±n
Otomatik Tespiti
```

**Alt Bilgi**:

- Proje AdÄ±: Multi-Label Retinal Disease Classification
- Model: ConvNeXt-Tiny (Transfer Learning)
- Framework: PyTorch
- Veri Seti: RFMiD Dataset (3200 fundus gÃ¶rÃ¼ntÃ¼sÃ¼)

**GÃ¶rsel**:

- Arka planda fundus gÃ¶rÃ¼ntÃ¼sÃ¼ kolajÄ± (bulanÄ±k/opacity %30)
- Veya: GÃ¶z ve yapay zeka birleÅŸimi temsili gÃ¶rsel

---

## SLIDE 2-3: Problem TanÄ±mÄ± ve Motivasyon

### ğŸ“Š SLIDE 2: Problem TanÄ±mÄ±

**BaÅŸlÄ±k**: "Problem: Retinal HastalÄ±klar ve TeÅŸhis ZorluÄŸu"

**Bullet Points**:

- ğŸ‘ï¸ **Retinal hastalÄ±klar** dÃ¼nya Ã§apÄ±nda kÃ¶rlÃ¼ÄŸÃ¼n Ã¶nde gelen nedenlerinden
- â° **Manuel teÅŸhis** zaman alÄ±cÄ± ve uzmanlÄ±k gerektiriyor
- ğŸŒ **Uzman hekim** eriÅŸimi kÄ±sÄ±tlÄ± (Ã¶zellikle geliÅŸmekte olan Ã¼lkelerde)
- ğŸ”¬ **Erken teÅŸhis** kritik - kÃ¶rlÃ¼ÄŸÃ¼ Ã¶nleyebilir
- ğŸ“ˆ **YaÅŸlanan nÃ¼fus** â†’ artan teÅŸhis ihtiyacÄ±

**GÃ¶rseller**:

- Normal gÃ¶z vs hastalÄ±klÄ± gÃ¶z anatomisi
- Ä°statistik grafiÄŸi: Retinal hastalÄ±k prevalansÄ±

**KonuÅŸma NotlarÄ±**:

```
Diyabetik retinopati tek baÅŸÄ±na dÃ¼nyada 93 milyon kiÅŸiyi etkiliyor.
Oftalmologlar her gÃ¼n yÃ¼zlerce fundus gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ incelemek zorunda.
Bu sÃ¼reÃ§ yorucu ve hataya aÃ§Ä±k. Yapay zeka bu sÃ¼reci hÄ±zlandÄ±rabilir
ve tutarlÄ± sonuÃ§lar verebilir.
```

---

### ğŸ“Š SLIDE 3: Proje AmacÄ± ve YaklaÅŸÄ±m

**BaÅŸlÄ±k**: "Ã‡Ã¶zÃ¼m: Multi-Label Deep Learning Classifier"

**AmaÃ§**:

```
Fundus gÃ¶rÃ¼ntÃ¼lerinden otomatik olarak 16 farklÄ± retinal
hastalÄ±ÄŸÄ± tespit edebilen bir yapay zeka sistemi geliÅŸtirmek
```

**Ã–zellikler**:

- âœ… **Multi-Label Classification**: Tek gÃ¶rÃ¼ntÃ¼de birden fazla hastalÄ±k tespiti
- âœ… **Transfer Learning**: ImageNet pre-trained ConvNeXt-Tiny
- âœ… **YÃ¼ksek DoÄŸruluk**: Test accuracy ~98.5%
- âœ… **HÄ±zlÄ± Ã‡Ä±karÄ±m**: GerÃ§ek zamanlÄ± tahmin imkanÄ±

**Tablo**: Problem Ã–zeti
| Girdi | Model | Ã‡Ä±ktÄ± |
|-------|-------|-------|
| Fundus GÃ¶rÃ¼ntÃ¼sÃ¼ (224Ã—224) | ConvNeXt-Tiny | 16 hastalÄ±k olasÄ±lÄ±ÄŸÄ± (0-1) |

**GÃ¶rsel**:

- Pipeline diyagramÄ±: Fundus Image â†’ ConvNeXt â†’ Disease Predictions

---

## SLIDE 4-8: Veri Seti ve GÃ¶rselleÅŸtirme

### ğŸ“Š SLIDE 4: Veri Seti Ã–zeti

**BaÅŸlÄ±k**: "RFMiD Dataset: Retinal Fundus Multi-Disease"

**Ä°statistikler Tablosu**:
| Ã–zellik | DeÄŸer |
|---------|-------|
| **Kaynak** | Kaggle - RFMiD Challenge |
| **Toplam GÃ¶rÃ¼ntÃ¼** | 3200 fundus gÃ¶rÃ¼ntÃ¼sÃ¼ |
| **EÄŸitim Seti** | 1920 gÃ¶rÃ¼ntÃ¼ (60%) |
| **Validation Seti** | 640 gÃ¶rÃ¼ntÃ¼ (20%) |
| **Test Seti** | 640 gÃ¶rÃ¼ntÃ¼ (20%) |
| **Orijinal Boyut** | DeÄŸiÅŸken (yeniden boyutlandÄ±rÄ±ldÄ±) |
| **Ä°ÅŸlenmiÅŸ Boyut** | 224Ã—224Ã—3 (RGB) |
| **Toplam SÄ±nÄ±f** | 16 retinal hastalÄ±k |
| **Multi-Label** | Evet (0-5 hastalÄ±k/gÃ¶rÃ¼ntÃ¼) |

**GÃ¶rsel**:

- Fundus gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¶rnekleri (grid: 3Ã—3)
- Dataset split pie chart (Train/Val/Test)

**KonuÅŸma NotlarÄ±**:

```
NOTEBOOK HÃœCRESÄ°: Cell #3 - CSV temizleme
20'den az Ã¶rneÄŸi olan 4 sÄ±nÄ±f Ã§Ä±karÄ±ldÄ± (MS, AH, AION, EDN).
Ã‡Ã¼nkÃ¼ bu kadar az veriyle model eÄŸitmek overfitting'e yol aÃ§ar.
Final sÄ±nÄ±f sayÄ±sÄ±: 16
```

---

### ğŸ“Š SLIDE 5: Tespit Edilen 16 HastalÄ±k

**BaÅŸlÄ±k**: "Classification Target: 16 Retinal Diseases"

**Ä°ki SÃ¼tunlu Liste**:

**SÃ¼tun 1**:

1. DR (Diabetic Retinopathy) - Diyabetik Retinopati
2. ARMD (Age-Related Macular Degeneration) - YaÅŸa BaÄŸlÄ± Makula Dejenerasyonu
3. MH (Macular Hole) - Makula DeliÄŸi
4. DN (Diabetic Nephropathy) - Diyabetik Nefropati
5. MYA (Myopia) - Miyopi
6. BRVO (Branch Retinal Vein Occlusion) - Retinal Ven TÄ±kanÄ±klÄ±ÄŸÄ±
7. TSLN (Tessellation) - Tessellasyon
8. ERM (Epiretinal Membrane) - Epiretinal Membran

**SÃ¼tun 2**: 9. LS (Laser Scars) - Lazer Ä°zleri 10. CSR (Central Serous Retinopathy) - Merkezi SerÃ¶z Retinopati 11. ODC (Optic Disc Cupping) - Optik Disk Ã‡ukurlaÅŸmasÄ± 12. CRVO (Central Retinal Vein Occlusion) - Merkezi Retinal Ven TÄ±kanÄ±klÄ±ÄŸÄ± 13. TV (Tortuous Vessels) - KÄ±vrÄ±mlÄ± Damarlar 14. VH (Vitreous Hemorrhage) - Vitreus KanamasÄ± 15. MHL (Macular Hole Large) - BÃ¼yÃ¼k Makula DeliÄŸi 16. ODP (Optic Disc Pallor) - Optik Disk SolukluÄŸu

**Not Kutusu**:

```
âš ï¸ Orijinal dataset 45 sÄ±nÄ±f iÃ§eriyordu.
ğŸ“Š 20'den az Ã¶rneÄŸi olan sÄ±nÄ±flar Ã§Ä±karÄ±ldÄ±.
âœ… Final: 16 yÃ¼ksek kaliteli sÄ±nÄ±f
```

---

### ğŸ“Š SLIDE 6: Multi-Label Classification

**BaÅŸlÄ±k**: "Multi-Label Problem: Bir GÃ¶rÃ¼ntÃ¼de 0-5 HastalÄ±k"

**Sol Taraf - AÃ§Ä±klama**:

```
Geleneksel Classification (Single-Label):
GÃ¶rÃ¼ntÃ¼ â†’ 1 sÄ±nÄ±f (Ã¶rn: "Kedi" VEYA "KÃ¶pek")

Multi-Label Classification:
GÃ¶rÃ¼ntÃ¼ â†’ 0+ sÄ±nÄ±f (Ã¶rn: "DR" VE "ARMD" VE "MH")
```

**SaÄŸ Taraf - Histogram**:

- X ekseni: GÃ¶rÃ¼ntÃ¼ baÅŸÄ±na hastalÄ±k sayÄ±sÄ± (0, 1, 2, 3, 4, 5+)
- Y ekseni: Frekans
- Renk kodlu bar chart

**GÃ¶rsel**:

```
NOTEBOOK'TAN ALINACAK: Cell #14 histogram Ã§Ä±ktÄ±sÄ±
```

**Ä°statistik Kutusu**:

- 0 hastalÄ±k (Normal): ~X% gÃ¶rÃ¼ntÃ¼
- 1 hastalÄ±k: ~Y% gÃ¶rÃ¼ntÃ¼
- 2+ hastalÄ±k: ~Z% gÃ¶rÃ¼ntÃ¼
- Max hastalÄ±k sayÄ±sÄ±: 5

**KonuÅŸma NotlarÄ±**:

```
NOTEBOOK HÃœCRESÄ°: Cell #13 - HastalÄ±k sayÄ±sÄ± histogramÄ±
Bu multi-label yapÄ± tÄ±bbi teÅŸhiste gerÃ§ekÃ§i bir durum.
Bir hasta birden fazla gÃ¶z hastalÄ±ÄŸÄ±na sahip olabilir.
Binary Cross-Entropy Loss bu yapÄ±ya uygundur.
```

---

### ğŸ“Š SLIDE 7: SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± ve Dengesizlik

**BaÅŸlÄ±k**: "Challenge: Ciddi SÄ±nÄ±f DengesizliÄŸi"

**Ana GÃ¶rsel**:

- Yatay bar chart (uzunâ†’kÄ±sa sÄ±ralÄ±)
- En yaygÄ±n 10 hastalÄ±k Ã¶rnek sayÄ±sÄ±
- Renk kodu: YeÅŸil (>100 Ã¶rnek), SarÄ± (50-100), KÄ±rmÄ±zÄ± (<50)

```
NOTEBOOK'TAN ALINACAK: Cell #18-19 - SÄ±nÄ±f frekansÄ± grafiÄŸi
```

**Ã–rnek SayÄ±larÄ± (Tahminsel)**:

- DR: ~500 Ã¶rnek âœ…
- ARMD: ~350 Ã¶rnek âœ…
- ...
- [En nadir]: ~20 Ã¶rnek âš ï¸

**Problem Vurgusu**:

```
âš ï¸ En yaygÄ±n sÄ±nÄ±f: 500+ Ã¶rnek
âš ï¸ En nadir sÄ±nÄ±f: ~20 Ã¶rnek
ğŸ“Š 25:1 oranÄ±nda dengesizlik!
```

**Ã‡Ã¶zÃ¼m Ã–nizlemesi**:

```
â†’ Focal Loss
â†’ Class Weighting
â†’ Weighted Random Sampler
â†’ Data Augmentation
(Detaylar ileriki slide'larda)
```

---

### ğŸ“Š SLIDE 8: Ã–rnek GÃ¶rÃ¼ntÃ¼ler

**BaÅŸlÄ±k**: "Dataset Samples: 0 â†’ 5 HastalÄ±k"

**GÃ¶rsel Grid (2Ã—3)**:

- 6 fundus gÃ¶rÃ¼ntÃ¼sÃ¼
- Her birinin altÄ±nda hastalÄ±k sayÄ±sÄ± ve isimler

```
NOTEBOOK'TAN ALINACAK: Cell #16 - FarklÄ± hastalÄ±k sayÄ±lÄ± Ã¶rnekler

Ã–rnek yerleÅŸim:
[0 hastalÄ±k]  [1 hastalÄ±k]  [2 hastalÄ±k]
(Normal)      (DR)          (DR + ARMD)

[3 hastalÄ±k]  [4 hastalÄ±k]  [5 hastalÄ±k]
(DR+ARMD+MH)  (...)         (...)
```

**KonuÅŸma NotlarÄ±**:

```
Normal retina: Pembe-turuncu renk, net damar yapÄ±sÄ±, dÃ¼zenli disk.
HastalÄ±klÄ± retina: Lezyonlar, eksuda, kanama, deÄŸiÅŸken renk bÃ¶lgeleri.
5 hastalÄ±klÄ± Ã¶rnek oldukÃ§a nadir ama mevcut.
```

---

## SLIDE 9-13: Model Mimarisi - ConvNeXt

### ğŸ“Š SLIDE 9: Neden ConvNeXt?

**BaÅŸlÄ±k**: "Model SeÃ§imi: ConvNeXt-Tiny"

**Sol Taraf - Timeline**:

```
CNN Evrimi:
2012: AlexNet (60M param)
2014: VGG-16 (138M param)
2015: ResNet-50 (25M param)
2019: EfficientNet (5-66M param)
2022: ConvNeXt â† BÄ°Z BURADAYIZ
```

**SaÄŸ Taraf - Neden ConvNeXt?**:
âœ… **Modern CNN**: Vision Transformer'dan ilham alan tasarÄ±m  
âœ… **Dengeli**: 28M parametre - ne Ã§ok kÃ¼Ã§Ã¼k ne Ã§ok bÃ¼yÃ¼k  
âœ… **Transfer Learning**: ImageNet pre-trained  
âœ… **KanÄ±tlanmÄ±ÅŸ**: TÄ±bbi gÃ¶rÃ¼ntÃ¼leme literatÃ¼rÃ¼nde baÅŸarÄ±lÄ±  
âœ… **Verimli**: Daha az GPU belleÄŸi, daha hÄ±zlÄ± eÄŸitim

**KarÅŸÄ±laÅŸtÄ±rma Tablosu**:
| Model | Parametre | ImageNet Top-1 | Bizim Tercih |
|-------|-----------|----------------|--------------|
| ResNet-50 | 25M | 76.2% | âŒ Eski mimari |
| EfficientNet-B0 | 5M | 77.3% | âŒ Ã‡ok kÃ¼Ã§Ã¼k |
| **ConvNeXt-Tiny** | **28M** | **82.1%** | **âœ… SEÃ‡TIK** |
| ConvNeXt-Base | 89M | 83.8% | âŒ Ã‡ok bÃ¼yÃ¼k (overfitting riski) |

**KonuÅŸma NotlarÄ±**:

```
NOTEBOOK HÃœCRESÄ°: Cell #33 - Model tanÄ±mÄ±
ConvNeXt, 2022'de Meta AI tarafÄ±ndan geliÅŸtirildi.
"A ConvNet for the 2020s" makalesiyle tanÄ±tÄ±ldÄ±.
Transformer'larÄ±n baÅŸarÄ±sÄ±nÄ± CNN'lere uyarladÄ±lar.
28M parametre, 3200 gÃ¶rÃ¼ntÃ¼lÃ¼k veri setimiz iÃ§in idealdir.
```

---

### ğŸ“Š SLIDE 10: ConvNeXt Mimari DetaylarÄ±

**BaÅŸlÄ±k**: "ConvNeXt-Tiny Architecture"

**Ana GÃ¶rsel**: ConvNeXt Stage DiyagramÄ±

```
INPUT (224Ã—224Ã—3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEM (Patchify)        â”‚
â”‚  Conv 4Ã—4, stride=4     â”‚
â”‚  96 filters             â”‚
â”‚  Output: 56Ã—56Ã—96       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1                â”‚
â”‚  3Ã— ConvNeXt Blocks     â”‚
â”‚  Output: 56Ã—56Ã—96       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2 (Downsample)   â”‚
â”‚  3Ã— ConvNeXt Blocks     â”‚
â”‚  Output: 28Ã—28Ã—192      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3 (Downsample)   â”‚
â”‚  9Ã— ConvNeXt Blocks     â”‚
â”‚  Output: 14Ã—14Ã—384      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4 (Downsample)   â”‚
â”‚  3Ã— ConvNeXt Blocks     â”‚
â”‚  Output: 7Ã—7Ã—768        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Global Avg Pool
    â†“
Classifier FC (768â†’16)
    â†“
Sigmoid (Multi-label)
    â†“
16 Disease Probabilities
```

**Stage Ã–zet Tablosu**:
| Stage | Ã‡Ä±kÄ±ÅŸ Boyutu | Kanallar | Blok SayÄ±sÄ± | Parametre |
|-------|--------------|----------|-------------|-----------|
| Stem | 56Ã—56 | 96 | 1 | ~90K |
| Stage 1 | 56Ã—56 | 96 | 3 | ~1.3M |
| Stage 2 | 28Ã—28 | 192 | 3 | ~2.5M |
| Stage 3 | 14Ã—14 | 384 | 9 | ~15M |
| Stage 4 | 7Ã—7 | 768 | 3 | ~9M |
| **Toplam** | - | - | **18 blok** | **~28M** |

---

### ğŸ“Š SLIDE 11: ConvNeXt Block Anatomisi

**BaÅŸlÄ±k**: "ConvNeXt Block: Transformer'dan Ä°lham"

**GÃ¶rsel**: ConvNeXt Block DiyagramÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    INPUT FEATURE MAP        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Depthwise Conv 7Ã—7         â”‚ â† BÃ¼yÃ¼k receptive field
â”‚  (Her kanal iÃ§in ayrÄ±)      â”‚    (ViT'deki attention benzeri)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer Normalization        â”‚ â† Batch Norm yerine
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pointwise Conv 1Ã—1         â”‚ â† Kanal geniÅŸletme (4Ã—)
â”‚  768 â†’ 3072 kanallar        â”‚    Inverted Bottleneck
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GELU Activation            â”‚ â† ReLU yerine (Transformer'dan)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pointwise Conv 1Ã—1         â”‚ â† Kanal daraltma
â”‚  3072 â†’ 768 kanallar        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Residual Connection (+)    â”‚ â† ResNet'ten kalma
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OUTPUT FEATURE MAP        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Temel TasarÄ±m Prensipleri**:

1. **Depthwise Conv 7Ã—7**: GeniÅŸ receptive field (ViT'deki attention window)
2. **Layer Normalization**: Batch Norm'dan daha stabil
3. **Inverted Bottleneck**: Darâ†’GeniÅŸâ†’Dar (MobileNet'ten)
4. **GELU**: Transformer'larda kullanÄ±lan aktivasyon
5. **Residual**: Gradient flow iÃ§in

---

### ğŸ“Š SLIDE 12: Transfer Learning Stratejisi

**BaÅŸlÄ±k**: "Transfer Learning: ImageNet â†’ Retinal Diseases"

**Sol Taraf - ImageNet Pre-training**:

```
ImageNet Dataset:
â”œâ”€ 1.2 milyon gÃ¶rÃ¼ntÃ¼
â”œâ”€ 1000 sÄ±nÄ±f (kÃ¶pek, kedi, araba...)
â””â”€ 476 GB veri

ConvNeXt-Tiny eÄŸitimi:
â”œâ”€ 300 epoch
â”œâ”€ Top-1 Accuracy: 82.1%
â””â”€ Ã–ÄŸrenilen Ã¶zellikler:
    â”œâ”€ DÃ¼ÅŸÃ¼k seviye: Kenar, renk, doku
    â”œâ”€ Orta seviye: Åekil, pattern
    â””â”€ YÃ¼ksek seviye: Nesne parÃ§alarÄ±
```

**SaÄŸ Taraf - Fine-Tuning Pipeline**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ImageNet Pretrained     â”‚
â”‚  ConvNeXt-Tiny           â”‚
â”‚  (1000 sÄ±nÄ±f Ã§Ä±kÄ±ÅŸ)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SON LAYER DEÄÄ°ÅTÄ°R      â”‚
â”‚  1000 â†’ 16 sÄ±nÄ±f         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DISCRIMINATIVE LR       â”‚
â”‚  Backbone: 2e-4 (dÃ¼ÅŸÃ¼k)  â”‚
â”‚  Classifier: 2e-3 (yÃ¼ksek)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FINE-TUNE               â”‚
â”‚  30 epoch                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retinal Disease         â”‚
â”‚  Classifier âœ…           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Neden Transfer Learning?**:
| Metrik | SÄ±fÄ±rdan EÄŸitim | Transfer Learning |
|--------|-----------------|-------------------|
| EÄŸitim SÃ¼resi | 50-100 epoch | 25-30 epoch |
| Convergence | YavaÅŸ, kararsÄ±z | HÄ±zlÄ±, stabil |
| Test Accuracy | ~70-85% | **~98.5%** |
| Overfitting | YÃ¼ksek risk | DÃ¼ÅŸÃ¼k risk |
| GPU Saati | 10-15 saat | 3-5 saat |

**KonuÅŸma NotlarÄ±**:

```
NOTEBOOK HÃœCRESÄ°: Cell #33 - models.convnext_tiny(weights='IMAGENET1K_V1')
ImageNet'te kedi-kÃ¶pek ayÄ±rt eden filtreler, retina'da damar-leke ayÄ±rt edebilir.
AÄŸaÃ§ yapraklarÄ±â†’gÃ¶z dokularÄ± benzer pattern recognition gerektirir.
Transfer learning kÃ¼Ã§Ã¼k veri setlerinde oyun deÄŸiÅŸtiricidir.
```

---

### ğŸ“Š SLIDE 13: Bizim Model KonfigÃ¼rasyonu

**BaÅŸlÄ±k**: "Final Model: Multi-Label Retinal Disease Classifier"

**Pipeline DiyagramÄ±**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          INPUT: Fundus Image (224Ã—224Ã—3)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FEATURE EXTRACTOR (ConvNeXt Backbone)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Stage 1-4: 18 ConvNeXt Blocks         â”‚     â”‚
â”‚  â”‚  ImageNet pretrained weights           â”‚     â”‚
â”‚  â”‚  ğŸ”’ Learning Rate: 2e-4 (dÃ¼ÅŸÃ¼k)        â”‚     â”‚
â”‚  â”‚  Ã–ÄŸrenilmiÅŸ Ã¶zellikleri koru           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  Output: 7Ã—7Ã—768 feature maps                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GLOBAL AVERAGE POOLING                   â”‚
â”‚         7Ã—7Ã—768 â†’ 768 vector                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CLASSIFIER (Task-Specific Head)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Fully Connected: 768 â†’ 16             â”‚     â”‚
â”‚  â”‚  SÄ±fÄ±rdan baÅŸlatÄ±ldÄ± (random init)     â”‚     â”‚
â”‚  â”‚  ğŸš€ Learning Rate: 2e-3 (yÃ¼ksek)       â”‚     â”‚
â”‚  â”‚  HÄ±zla yeni gÃ¶reve adapte ol           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       SIGMOID ACTIVATION (per-class)             â”‚
â”‚       16 baÄŸÄ±msÄ±z sigmoid (multi-label)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    OUTPUT: 16 Disease Probabilities (0-1)        â”‚
â”‚    Threshold=0.5 â†’ Binary predictions            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Model Ã–zellikleri Tablosu**:
| Parametre | DeÄŸer |
|-----------|-------|
| Backbone | ConvNeXt-Tiny |
| Pretrained Weights | ImageNet-1K (82.1% accuracy) |
| Input Size | 224 Ã— 224 Ã— 3 (RGB) |
| Feature Dimension | 768 |
| Output Classes | 16 (retinal diseases) |
| Total Parameters | 28,589,128 (~28.6M) |
| Trainable Parameters | 28,589,128 (tÃ¼mÃ¼ trainable) |
| Output Activation | Sigmoid (per-class, multi-label) |
| Loss Function | BCEWithLogitsLoss (weighted) |
| Optimizer | AdamW (discriminative LR) |

**Code Snippet** (Slide alt kÃ¶ÅŸe):

```python
# NOTEBOOK Cell #33
model = models.convnext_tiny(weights='IMAGENET1K_V1')
in_features = model.classifier[-1].in_features  # 768
OUT_FINAL = 16  # 16 hastalÄ±k sÄ±nÄ±fÄ±
model.classifier[-1] = nn.Linear(in_features, OUT_FINAL)
```

**KonuÅŸma NotlarÄ±**:

```
NOTEBOOK HÃœCRESÄ°: Cell #33-34
Toplam 28.6M parametre - hepsi eÄŸitiliyor (frozen layer yok).
Discriminative LR ile backbone koruyucu, classifier agresif Ã¶ÄŸreniyor.
Multi-label iÃ§in sigmoid kullanÄ±yoruz (softmax deÄŸil).
Her hastalÄ±k iÃ§in baÄŸÄ±msÄ±z 0-1 olasÄ±lÄ±k Ã§Ä±ktÄ±sÄ±.
```

---

## SLIDE 14-16: Transfer Learning DetaylarÄ±

### ğŸ“Š SLIDE 14: Discriminative Fine-Tuning

**BaÅŸlÄ±k**: "Discriminative Fine-Tuning: Ä°ki HÄ±zlÄ± Ã–ÄŸrenme"

**Konsept AÃ§Ä±klama**:

```
Fikir: FarklÄ± katmanlar farklÄ± hÄ±zlarda Ã¶ÄŸrenmeli

Backbone (Features):
  â”œâ”€ ImageNet'ten geldi
  â”œâ”€ Zaten iyi Ã¶zellikler Ã¶ÄŸrenmiÅŸ
  â””â”€ â†’ KÃ¼Ã§Ã¼k adÄ±mlarla ince ayar yap
      LR = 2e-4 (dÃ¼ÅŸÃ¼k)

Classifier (Head):
  â”œâ”€ SÄ±fÄ±rdan baÅŸladÄ± (random weights)
  â”œâ”€ Yeni gÃ¶rev iÃ§in Ã¶ÄŸrenmeli
  â””â”€ â†’ BÃ¼yÃ¼k adÄ±mlarla hÄ±zla Ã¶ÄŸren
      LR = 2e-3 (yÃ¼ksek - 10Ã— fazla)
```

**Learning Rate GrafiÄŸi**:

```
Learning Rate DeÄŸerleri:

Classifier (Head)     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2e-3

Backbone (Features)   â–ˆâ–ˆâ–ˆâ–ˆ 2e-4

                      0    5e-4  1e-3  1.5e-3  2e-3
```

**Code Implementation**:

```python
# NOTEBOOK Cell #43
LR_FOUND = 2e-3  # LR Finder'dan

lr_params = [
    {'params': model.features.parameters(),
     'lr': LR_FOUND / 10},  # 2e-4 (backbone)

    {'params': model.classifier.parameters(),
     'lr': LR_FOUND}  # 2e-3 (classifier)
]

optimizer = optim.AdamW(lr_params)
```

**AvantajlarÄ±**:
âœ… Pretrained bilgi korunur (catastrophic forgetting Ã¶nlenir)  
âœ… Yeni gÃ¶rev hÄ±zla Ã¶ÄŸrenilir  
âœ… Daha iyi genelleme  
âœ… Overfitting riski azalÄ±r

**Kaynak**: ULMFiT paper (Howard & Ruder, 2018)

---

### ğŸ“Š SLIDE 15: Learning Rate Finder

**BaÅŸlÄ±k**: "Optimal Learning Rate: LR Range Test"

**Sol Taraf - LR Finder GrafiÄŸi**:

```
NOTEBOOK'TAN ALINACAK: Cell #39 - LR Finder plot

Learning Rate vs Loss:
  â”‚
L â”‚    â•±â”€â”€â”€â”€â”€â•²___
o â”‚   â•±          â•²___
s â”‚  â•±               â•²____
s â”‚ â•±                     â•²____
  â”‚â•±                           â•²_____
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
   1e-7  1e-5   1e-3  1e-1  10
          â†‘
       En dÃ¼ÅŸÃ¼k
       nokta: ~2e-2
```

**SaÄŸ Taraf - SeÃ§im Kriteri**:

```
LR SeÃ§im KuralÄ± (Cyclical LR paper):

1ï¸âƒ£ En dÃ¼ÅŸÃ¼k loss noktasÄ±: ~2e-2
2ï¸âƒ£ Bunu 10'a bÃ¶l: 2e-2 / 10 = 2e-3
3ï¸âƒ£ SONUÃ‡: LR = 2e-3 âœ…

Neden bÃ¶yle?
â†’ Ã‡ok yÃ¼ksek LR: Diverge eder
â†’ Ã‡ok dÃ¼ÅŸÃ¼k LR: Ã‡ok yavaÅŸ Ã¶ÄŸrenir
â†’ Loss minimumdan 1 kat Ã¶nce: Optimal
```

**LR Finder AlgoritmasÄ±**:

```
1. Model baÅŸlat (ImageNet weights)
2. Ã‡ok dÃ¼ÅŸÃ¼k LR'den baÅŸla (1e-7)
3. Her mini-batch sonrasÄ± LR'yi artÄ±r
4. Loss'u kaydet
5. Loss diverge edene kadar devam et
6. Loss-LR grafiÄŸi Ã§iz
7. En iyi LR'yi seÃ§
```

**Kod**:

```python
# NOTEBOOK Cell #37-38
START_LR = 1e-7
END_LR = 10
NUM_ITER = 100

lr_finder = LRFinder(model, optimizer, loss_fn, device)
lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)
```

**KonuÅŸma NotlarÄ±**:

```
LR Finder, Cyclical Learning Rates makalesinden (Smith, 2017).
Manuel LR seÃ§imi yerine sistematik yaklaÅŸÄ±m.
100 iterasyonda 1e-7'den 10'a exponential artÄ±ÅŸ.
En iyi LR: 2e-3 (grafikten okundu).
```

---

### ğŸ“Š SLIDE 16: Transfer Learning SonuÃ§larÄ±

**BaÅŸlÄ±k**: "Transfer Learning Impact: With vs Without"

**KarÅŸÄ±laÅŸtÄ±rma Tablosu**:
| Metrik | SÄ±fÄ±rdan EÄŸitim (Tahmin) | Transfer Learning (GerÃ§ek) | Ä°yileÅŸme |
|--------|--------------------------|----------------------------|----------|
| **Convergence** | 50-80 epoch | **25-30 epoch** | 2-3Ã— hÄ±zlÄ± |
| **Ä°lk Epoch Loss** | ~0.85 | **~0.45** | 47% dÃ¼ÅŸÃ¼k |
| **Final Loss** | ~0.15 | **~0.05** | 66% dÃ¼ÅŸÃ¼k |
| **Test Accuracy** | ~75-85% | **~98.5%** | +13-23% |
| **Overfitting** | YÃ¼ksek risk | DÃ¼ÅŸÃ¼k risk | âœ… |
| **GPU Saati** | 10-15 saat | **3-5 saat** | 3Ã— hÄ±zlÄ± |
| **Parametre Update** | 28.6M (tÃ¼mÃ¼) | 28.6M (farklÄ± hÄ±zlar) | Discriminative |

**GÃ¶rsel: Training Curve KarÅŸÄ±laÅŸtÄ±rmasÄ±**:

```
Training Loss:

1.0â”‚                Random Init â•±â”€â”€â”€â”€â•²___
   â”‚                          â•±         â•²__
0.5â”‚      Transfer Learning â•±               â•²_
   â”‚                       â•±___________________â•²____
0.0â”‚____________________________â†’
    0    10    20    30   40    50   60   70   80
           Epoch
```

**Neden Bu Kadar Etkili?**:

```
ImageNet'te Ã¶ÄŸrenilen:
âœ“ Kenar detektÃ¶rler â†’ Damar kenarlarÄ±
âœ“ Doku pattern'leri â†’ Retina dokularÄ±
âœ“ Renk Ã¶zellikleri â†’ Lezyon renkleri
âœ“ Åekil tanÄ±ma â†’ Disk, makula ÅŸekli
âœ“ Anomali tespiti â†’ HastalÄ±k iÅŸaretleri

SÄ±fÄ±rdan Ã¶ÄŸrenmek zorunda kalsaydÄ±k:
âœ— 3200 gÃ¶rÃ¼ntÃ¼ Ã§ok az
âœ— Overfitting garantisi
âœ— Ã‡ok uzun eÄŸitim sÃ¼resi
âœ— DÃ¼ÅŸÃ¼k performans
```

**SonuÃ§**:

```
ğŸ¯ Transfer Learning ZORUNLU kÃ¼Ã§Ã¼k tÄ±bbi veri setlerinde!
ğŸ“Š ImageNet pretraining = 10+ kat veri artÄ±rma etkisi
âœ… ConvNeXt-Tiny ideal backbone seÃ§imi
```

---

## 4. Veri Ã–n Ä°ÅŸleme ve Augmentation

### SÃ¶ylenebilecekler:

- **Normalizasyon**: ImageNet istatistikleri kullanÄ±ldÄ± (mean, std)
- **Temel Augmentation**:
  - Resize (224x224)
  - Random Rotation (180Â°)
  - Horizontal/Vertical Flip (%50)
  - Sharpness Adjustment
  - Center Crop
- **GeliÅŸmiÅŸ Augmentation**:
  - **ColorJitter**: ParlaklÄ±k, kontrast, doygunluk, ton deÄŸiÅŸimleri
  - **RandomAffine**: DÃ¶ndÃ¼rme, Ã¶teleme, Ã¶lÃ§ekleme, eÄŸme
  - **GaussianBlur**: BulanÄ±klÄ±k efekti
  - **Random Erasing (Cutout)**: Rastgele bÃ¶lge silme - overfitting'e karÅŸÄ±

### Neden Bu Augmentation'lar?

- Retinal gÃ¶rÃ¼ntÃ¼ler farklÄ± aÃ§Ä±lardan Ã§ekilebilir â†’ Rotation gerekli
- AydÄ±nlatma koÅŸullarÄ± deÄŸiÅŸken â†’ ColorJitter gerekli
- KÃ¼Ã§Ã¼k veri seti â†’ Daha fazla augmentation = daha iyi genelleme

### GÃ¶sterilebilecek GÃ¶rseller:

- AynÄ± gÃ¶rÃ¼ntÃ¼nÃ¼n farklÄ± augmentation versiyonlarÄ±
- Augmentation Ã¶ncesi vs sonrasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 5. SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler

### SÃ¶ylenebilecekler:

- **Problem**: 43 sÄ±nÄ±f arasÄ±nda ciddi dengesizlik
  - En yaygÄ±n sÄ±nÄ±f: ~500 Ã¶rnek
  - En nadir sÄ±nÄ±f: <10 Ã¶rnek
- **Ã‡Ã¶zÃ¼mler**:

#### 1. Focal Loss

- Standart BCE loss'un geliÅŸtirilmiÅŸ versiyonu
- Kolay Ã¶rnekleri down-weight eder, zor Ã¶rneklere odaklanÄ±r
- FormÃ¼l: FL(p_t) = -Î±(1-p_t)^Î³ log(p_t)
- Î³ (gamma) = 2.0 kullanÄ±ldÄ±

#### 2. Weighted BCE Loss

- Pozitif sÄ±nÄ±flara daha yÃ¼ksek aÄŸÄ±rlÄ±k verilir
- pos_weight = (negatif Ã¶rnek sayÄ±sÄ±) / (pozitif Ã¶rnek sayÄ±sÄ±)

#### 3. Asymmetric Loss

- Pozitif ve negatif Ã¶rnekler iÃ§in farklÄ± gamma deÄŸerleri
- Negatif baskÄ±n veri setleri iÃ§in Ã¶zellikle etkili

#### 4. Weighted Random Sampler

- Her batch'te sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± dengelemek iÃ§in kullanÄ±lÄ±r

### GÃ¶sterilebilecek GÃ¶rseller:

- SÄ±nÄ±f frekansÄ± vs F1 score grafiÄŸi
- Orijinal vs iyileÅŸtirilmiÅŸ model F1 karÅŸÄ±laÅŸtÄ±rmasÄ±
- Focal Loss vs BCE Loss karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 6. EÄŸitim Stratejisi

### SÃ¶ylenebilecekler:

#### Optimizer: AdamW

- Adam + Weight Decay (L2 regularization)
- Weight Decay: 1e-4

#### Learning Rate Stratejisi:

- **LR Finder** kullanÄ±larak optimal LR belirlendi
- **Discriminative Fine-tuning**:
  - Feature extractor: LR = 2e-4 (dÃ¼ÅŸÃ¼k)
  - Classifier: LR = 2e-3 (yÃ¼ksek)
  - Ã–nceden Ã¶ÄŸrenilmiÅŸ Ã¶zellikler korunur, classifier hÄ±zla adapte olur

#### Scheduler: Cosine Annealing

- Learning rate zamanla azalarak 1e-6'ya dÃ¼ÅŸer
- Daha yumuÅŸak optimizasyon

#### EÄŸitim AyarlarÄ±:

- Batch Size: 64
- Epoch SayÄ±sÄ±: 30
- Early Stopping Patience: 5
- Gradient Clipping: 1.0 (gradyan patlamasÄ±nÄ± Ã¶nler)

### GÃ¶sterilebilecek GÃ¶rseller:

- LR Finder grafiÄŸi
- Training vs Validation Loss/Accuracy eÄŸrileri
- Learning Rate schedule grafiÄŸi

---

## 7. SonuÃ§lar ve Performans

### SÃ¶ylenebilecekler:

#### Test Metrikleri:

| Metrik                      | DeÄŸer  |
| --------------------------- | ------ |
| Test Accuracy               | %98.5  |
| Test Loss                   | 0.0494 |
| Ã–ÄŸrenilen SÄ±nÄ±flar (F1 > 0) | 16/43  |
| En Ä°yi SÄ±nÄ±flar F1          | %70-80 |

#### DetaylÄ± Analiz:

- **Yeterli veri olan sÄ±nÄ±flar**: F1 score ~%70-80 baÅŸarÄ±
- **Nadir sÄ±nÄ±flar iki kategoriye ayrÄ±lÄ±yor**:
  1. Ä°yi Ã¶ÄŸrenilen ama dÃ¼ÅŸÃ¼k recall (precision > recall)
  2. HiÃ§ Ã¶ÄŸrenilemeyen sÄ±nÄ±flar (F1 = 0)
- **Multi-label Performans**: Birden fazla hastalÄ±ÄŸÄ± baÅŸarÄ±yla tespit edebiliyor

#### SÄ±nÄ±f BazlÄ± Metrikler:

- **Precision**: Model "hastalÄ±k var" dediÄŸinde ne kadar doÄŸru?
- **Recall**: GerÃ§ekte hastalÄ±k olanlarÄ±n ne kadarÄ± tespit edildi?
- **F1 Score**: Precision ve Recall'un harmonik ortalamasÄ±

### GÃ¶sterilebilecek GÃ¶rseller:

- Training/Validation loss ve accuracy eÄŸrileri
- SÄ±nÄ±f bazlÄ± Precision, Recall, F1 bar chart
- Confusion matrix (en yaygÄ±n 10 hastalÄ±k iÃ§in)
- Nadir sÄ±nÄ±flar iÃ§in confusion matrix grid
- ROC eÄŸrileri (seÃ§ili sÄ±nÄ±flar iÃ§in)
- Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi (Orijinal vs Ä°yileÅŸtirilmiÅŸ)

---

## 8. Demo ve Ã–rnek Tahminler

### SÃ¶ylenebilecekler:

- EÄŸitilmiÅŸ model ile yeni gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde tahmin yapÄ±labilir
- `inference.py` ile tek gÃ¶rÃ¼ntÃ¼ veya toplu tahmin desteÄŸi
- Threshold = 0.5 kullanÄ±larak multi-label tahminler

### Demo AkÄ±ÅŸÄ±:

1. Ã–rnek bir fundus gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kle
2. Model tahminlerini gÃ¶ster
3. OlasÄ±lÄ±k deÄŸerleri ile birlikte tespit edilen hastalÄ±klarÄ± listele

### KullanÄ±m:

```bash
# Tek gÃ¶rÃ¼ntÃ¼ tahmini
python inference.py --image ./test_image.png --model ./outputs/checkpoints/best_model.pth

# Toplu tahmin
python inference.py --folder ./test_images/ --output predictions.csv
```

### GÃ¶sterilebilecek GÃ¶rseller:

- Ã–rnek tahmin sonuÃ§larÄ± (gÃ¶rÃ¼ntÃ¼ + tespit edilen hastalÄ±klar)
- OlasÄ±lÄ±k Ã§Ä±ktÄ±larÄ± ile birlikte Ã¶rnek tahminler

---

## 9. SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar

### SÃ¶ylenebilecekler:

#### BaÅŸarÄ±lar:

- âœ… 43 sÄ±nÄ±flÄ± multi-label classification baÅŸarÄ±yla gerÃ§ekleÅŸtirildi
- âœ… Transfer learning ile sÄ±nÄ±rlÄ± veriyle yÃ¼ksek performans
- âœ… Focal Loss ile sÄ±nÄ±f dengesizliÄŸi kÄ±smen aÅŸÄ±ldÄ±
- âœ… %98.5 test accuracy elde edildi
- âœ… ModÃ¼ler, yeniden kullanÄ±labilir kod yapÄ±sÄ±

#### Limitasyonlar:

- âš ï¸ Nadir sÄ±nÄ±flarda dÃ¼ÅŸÃ¼k recall
- âš ï¸ BazÄ± Ã§ok nadir hastalÄ±klar (< 10 Ã¶rnek) Ã¶ÄŸrenilemiyor
- âš ï¸ Daha fazla veri ile performans artÄ±rÄ±labilir

#### Gelecek Ã‡alÄ±ÅŸmalar:

- ğŸ“ˆ Veri artÄ±rma: Daha fazla etiketli veri toplama
- ğŸ“ˆ Class-aware sampling stratejileri
- ğŸ“ˆ Knowledge distillation
- ğŸ“ˆ Ensemble modeller
- ğŸ“ˆ Explainability: Grad-CAM ile hastalÄ±k bÃ¶lgelerini gÃ¶rselleÅŸtirme
- ğŸ“ˆ Ã‡apraz doÄŸrulama (Cross-validation)
- ğŸ“ˆ Daha bÃ¼yÃ¼k ConvNeXt modelleri (Small, Base)

### GÃ¶sterilebilecek GÃ¶rseller:

- Proje Ã¶zet tablosu
- Gelecek Ã§alÄ±ÅŸmalar iÃ§in yol haritasÄ±

---

## ğŸ“Š Notebookta Mevcut Ã–nemli GÃ¶rseller

| GÃ¶rsel Tipi          | AÃ§Ä±klama                         | Notebook HÃ¼cresi |
| -------------------- | -------------------------------- | ---------------- |
| SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±       | HastalÄ±k baÅŸÄ±na Ã¶rnek sayÄ±sÄ±     | Cell #12-13      |
| Ã–rnek GÃ¶rÃ¼ntÃ¼ler     | 0-5 hastalÄ±k iÃ§eren fundus       | Cell #14-17      |
| Training Curves      | Loss ve Accuracy grafikleri      | Cell #78         |
| F1 KarÅŸÄ±laÅŸtÄ±rmasÄ±   | Orijinal vs Ä°yileÅŸtirilmiÅŸ model | Cell #50         |
| Confusion Matrix     | Top-10 sÄ±nÄ±flar iÃ§in             | Cell #80         |
| Nadir SÄ±nÄ±f CM       | En az Ã¶rneÄŸi olan 10 sÄ±nÄ±f       | Cell #52         |
| SÄ±nÄ±f FrekansÄ± vs F1 | Ä°yileÅŸme analizi                 | Cell #50         |
| Metrik Bar Chart     | Precision, Recall, F1            | Cell #75         |

---

## ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±

| Kategori       | Teknoloji                                 |
| -------------- | ----------------------------------------- |
| Framework      | PyTorch                                   |
| Model          | ConvNeXt-Tiny (ImageNet pretrained)       |
| Loss Functions | Focal Loss, Weighted BCE, Asymmetric Loss |
| Optimizer      | AdamW + Discriminative LR                 |
| Scheduler      | Cosine Annealing                          |
| Ortam          | Google Colab (GPU) / Local                |
| Veri Ä°ÅŸleme    | torchvision transforms                    |
| GÃ¶rselleÅŸtirme | matplotlib, seaborn                       |
| Metrikler      | sklearn, custom metrics                   |

---

## ğŸ“š Kaynaklar

1. **RFMiD Dataset**: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification
2. **ConvNeXt Paper**: Liu et al., "A ConvNet for the 2020s", CVPR 2022
3. **Focal Loss Paper**: Lin et al., "Focal Loss for Dense Object Detection", ICCV 2017
4. **Asymmetric Loss Paper**: Ridnik et al., "Asymmetric Loss For Multi-Label Classification", ICCV 2021
