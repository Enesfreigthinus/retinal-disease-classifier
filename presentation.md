# Retinal Disease Classifier - Sunum TaslaÄŸÄ±

## ğŸ“‹ Ä°Ã§indekiler

1. [GiriÅŸ ve Problem TanÄ±mÄ±](#1-giriÅŸ-ve-problem-tanÄ±mÄ±)
2. [Veri Seti](#2-veri-seti)
3. [Model Mimarisi](#3-model-mimarisi)
4. [Veri Ã–n Ä°ÅŸleme ve Augmentation](#4-veri-Ã¶n-iÅŸleme-ve-augmentation)
5. [SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler](#5-sÄ±nÄ±f-dengesizliÄŸi-ve-Ã§Ã¶zÃ¼mler)
6. [EÄŸitim Stratejisi](#6-eÄŸitim-stratejisi)
7. [SonuÃ§lar ve Performans](#7-sonuÃ§lar-ve-performans)
8. [Demo ve Ã–rnek Tahminler](#8-demo-ve-Ã¶rnek-tahminler)
9. [SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar](#9-sonuÃ§-ve-gelecek-Ã§alÄ±ÅŸmalar)

---

## 1. GiriÅŸ ve Problem TanÄ±mÄ±

### SÃ¶ylenebilecekler:

- **Problem**: Retinal (gÃ¶z dibi) gÃ¶rÃ¼ntÃ¼lerinden hastalÄ±k tespiti, oftalmologlar iÃ§in zaman alÄ±cÄ± ve uzmanlÄ±k gerektiren bir sÃ¼reÃ§tir.
- **Motivasyon**: Diyabetik retinopati, yaÅŸa baÄŸlÄ± makula dejenerasyonu gibi hastalÄ±klarÄ±n erken tespiti kÃ¶rlÃ¼ÄŸÃ¼ Ã¶nleyebilir.
- **AmaÃ§**: Fundus gÃ¶rÃ¼ntÃ¼lerinden otomatik olarak **43 farklÄ± retinal hastalÄ±ÄŸÄ±** tespit edebilen bir derin Ã¶ÄŸrenme modeli geliÅŸtirmek.
- **Multi-label Classification**: Tek bir gÃ¶rÃ¼ntÃ¼de birden fazla hastalÄ±k aynÄ± anda bulunabilir (Ã¶rn: hem diyabetik retinopati hem makula dejenerasyonu).
- **Klinik Ã–nemi**: Yapay zeka destekli tanÄ± sistemleri, Ã¶zellikle uzman hekim eriÅŸiminin kÄ±sÄ±tlÄ± olduÄŸu bÃ¶lgelerde hayat kurtarÄ±cÄ± olabilir.

### GÃ¶sterilebilecek GÃ¶rseller:

- Normal vs hastalÄ±klÄ± retina gÃ¶rÃ¼ntÃ¼sÃ¼ karÅŸÄ±laÅŸtÄ±rmasÄ± (notebook'ta mevcut)
- 0'dan 5'e kadar hastalÄ±k iÃ§eren Ã¶rnek fundus gÃ¶rÃ¼ntÃ¼leri

---

## 2. Veri Seti

### SÃ¶ylenebilecekler:

- **Kaynak**: RFMiD (Retinal Fundus Multi-disease Image Dataset) - Kaggle
- **Toplam GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±**: 3200 fundus gÃ¶rÃ¼ntÃ¼sÃ¼
  - EÄŸitim: 1920 gÃ¶rÃ¼ntÃ¼
  - DoÄŸrulama: 640 gÃ¶rÃ¼ntÃ¼
  - Test: 640 gÃ¶rÃ¼ntÃ¼
- **SÄ±nÄ±f SayÄ±sÄ±**: 43 farklÄ± retinal hastalÄ±k (HR ve ODPM hariÃ§ tutulmuÅŸtur)
- **GÃ¶rÃ¼ntÃ¼ Boyutu**: 224x224 piksel (yeniden boyutlandÄ±rÄ±lmÄ±ÅŸ)

### Tespit Edilen HastalÄ±klar:

- Diyabetik Retinopati (DR)
- YaÅŸa BaÄŸlÄ± Makula Dejenerasyonu (ARMD)
- Makula DeliÄŸi (MH)
- Diyabetik Nefropati (DN)
- Miyopi (MYA)
- Retinal Ven TÄ±kanÄ±klÄ±ÄŸÄ± (BRVO)
- Ve 37 ek hastalÄ±k daha...

### Veri Seti ZorluklarÄ±:

- **Ciddi SÄ±nÄ±f DengesizliÄŸi**: BazÄ± hastalÄ±klar Ã§ok nadir (10'dan az Ã¶rnek), bazÄ±larÄ± yaygÄ±n (500+ Ã¶rnek)
- **Multi-label YapÄ±**: Bir gÃ¶rÃ¼ntÃ¼de 0-5+ hastalÄ±k bulunabilir

### GÃ¶sterilebilecek GÃ¶rseller:

- HastalÄ±k baÅŸÄ±na Ã¶rnek sayÄ±sÄ±nÄ± gÃ¶steren bar chart (sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±)
- GÃ¶rÃ¼ntÃ¼ baÅŸÄ±na hastalÄ±k sayÄ±sÄ± histogramÄ±
- FarklÄ± sayÄ±da hastalÄ±k iÃ§eren Ã¶rnek fundus gÃ¶rÃ¼ntÃ¼leri (0-5 hastalÄ±k)

---

## 3. Model Mimarisi

> **Toplam Slide SayÄ±sÄ±: 4 Slide**

---

### ğŸ“Œ Slide 3.1: Neden ConvNeXt?

#### Slide Ä°Ã§eriÄŸi:

- BaÅŸlÄ±k: "Model SeÃ§imi: Neden ConvNeXt-Tiny?"
- Alt baÅŸlÄ±k: "Modern CNN vs Geleneksel YaklaÅŸÄ±mlar"

#### GÃ¶rseller:

- CNN mimarilerinin kronolojik geliÅŸimi gÃ¶rseli (AlexNet â†’ VGG â†’ ResNet â†’ EfficientNet â†’ ConvNeXt)
- ConvNeXt vs ResNet vs ViT performans karÅŸÄ±laÅŸtÄ±rma tablosu (ImageNet sonuÃ§larÄ±)

#### AnlatÄ±m Metni:

> "Model seÃ§iminde neden ConvNeXt-Tiny'Ä± tercih ettik? ConvNeXt, 2022 yÄ±lÄ±nda Facebook AI Research (Meta) tarafÄ±ndan geliÅŸtirilmiÅŸ ve 'A ConvNet for the 2020s' baÅŸlÄ±klÄ± makale ile tanÄ±tÄ±lmÄ±ÅŸtÄ±r.
>
> ConvNeXt'in Ã¶zelliÄŸi, Vision Transformer'larÄ±n baÅŸarÄ±sÄ±ndan sonra CNN mimarilerinin hÃ¢lÃ¢ rekabetÃ§i olabileceÄŸini gÃ¶stermesidir. AraÅŸtÄ±rmacÄ±lar, ResNet mimarisini modern tasarÄ±m prensipleriyle gÃ¼ncellemiÅŸ ve ViT ile karÅŸÄ±laÅŸtÄ±rÄ±labilir performans elde etmiÅŸlerdir.
>
> Bizim projemiz iÃ§in ConvNeXt-Tiny ideal Ã§Ã¼nkÃ¼:
>
> - GÃ¶rece kÃ¼Ã§Ã¼k model boyutu (~28M parametre) ile yÃ¼ksek performans sunar
> - Transfer learning iÃ§in optimize edilmiÅŸtir
> - TÄ±bbi gÃ¶rÃ¼ntÃ¼ analizinde CNN'ler hÃ¢lÃ¢ Ã§ok etkilidir"

---

### ğŸ“Œ Slide 3.2: ConvNeXt Mimarisi DetaylarÄ±

#### Slide Ä°Ã§eriÄŸi:

- BaÅŸlÄ±k: "ConvNeXt-Tiny Mimari YapÄ±sÄ±"
- ConvNeXt bloÄŸu ÅŸemasÄ±
- Katman detaylarÄ± tablosu

#### GÃ¶rseller:

- ConvNeXt block diyagramÄ± (Depthwise Conv â†’ LayerNorm â†’ 1x1 Conv â†’ GELU â†’ 1x1 Conv)
- Stage yapÄ±sÄ± gÃ¶rseli (4 stage: 96â†’192â†’384â†’768 kanal)

#### Tablo (Slide'a eklenecek):

| Stage   | Ã‡Ä±kÄ±ÅŸ Boyutu | Kanal SayÄ±sÄ± | Blok SayÄ±sÄ± |
| ------- | ------------ | ------------ | ----------- |
| Stem    | 56Ã—56        | 96           | 1           |
| Stage 1 | 56Ã—56        | 96           | 3           |
| Stage 2 | 28Ã—28        | 192          | 3           |
| Stage 3 | 14Ã—14        | 384          | 9           |
| Stage 4 | 7Ã—7          | 768          | 3           |

#### AnlatÄ±m Metni:

> "ConvNeXt mimarisine daha yakÄ±ndan bakalÄ±m. Mimari 4 ana stage'den oluÅŸur ve her stage'de Ã¶zellik haritalarÄ±nÄ±n boyutu yarÄ±ya inerken kanal sayÄ±sÄ± iki katÄ±na Ã§Ä±kar.
>
> ConvNeXt bloÄŸunun temel bileÅŸenleri:
>
> 1. **Depthwise Convolution (7Ã—7)**: Her kanal iÃ§in ayrÄ± konvolÃ¼syon, hesaplama verimliliÄŸi saÄŸlar
> 2. **Layer Normalization**: Batch Norm yerine, daha stabil eÄŸitim
> 3. **Pointwise Convolutions (1Ã—1)**: Kanal etkileÅŸimlerini Ã¶ÄŸrenir
> 4. **GELU Aktivasyonu**: ReLU'dan daha yumuÅŸak, modern transformerlarda kullanÄ±lan aktivasyon
> 5. **Inverted Bottleneck**: Darâ†’GeniÅŸâ†’Dar yapÄ±sÄ±, parametre verimliliÄŸi
>
> Bu tasarÄ±m, ViT'in baÅŸarÄ±lÄ± Ã¶zelliklerini CNN'e adapte eder. Ã–rneÄŸin, bÃ¼yÃ¼k kernel boyutu (7Ã—7), transformer'daki geniÅŸ attention window'a karÅŸÄ±lÄ±k gelir."

---

### ğŸ“Œ Slide 3.3: Transfer Learning ve Fine-Tuning

#### Slide Ä°Ã§eriÄŸi:

- BaÅŸlÄ±k: "Transfer Learning Stratejimiz"
- Transfer learning akÄ±ÅŸ diyagramÄ±
- ImageNet pretraining aÃ§Ä±klamasÄ±

#### GÃ¶rseller:

- Transfer learning konsept gÃ¶rseli (ImageNet â†’ Retinal Disease)
- Feature extractor + Classifier ayrÄ±mÄ± gÃ¶rseli
- Discriminative Learning Rate grafiÄŸi

#### AnlatÄ±m Metni:

> "Projemizde transfer learning kullanÄ±yoruz. Peki bu ne anlama geliyor?
>
> ConvNeXt-Tiny modeli Ã¶nce ImageNet veri seti Ã¼zerinde eÄŸitilmiÅŸ. ImageNet, 1.2 milyon gÃ¶rÃ¼ntÃ¼ ve 1000 sÄ±nÄ±f iÃ§erir. Bu eÄŸitim sÄ±rasÄ±nda model:
>
> - Kenar, kÃ¶ÅŸe, doku gibi dÃ¼ÅŸÃ¼k seviyeli Ã¶zellikler
> - Åekil, pattern gibi orta seviyeli Ã¶zellikler
> - Nesne parÃ§alarÄ± gibi yÃ¼ksek seviyeli Ã¶zellikler Ã¶ÄŸrenmiÅŸtir.
>
> Bu Ã¶ÄŸrenilmiÅŸ Ã¶zellikler retinal gÃ¶rÃ¼ntÃ¼ler iÃ§in de geÃ§erlidir! Damarlar, lekeler, renk deÄŸiÅŸimleri benzer dÃ¼ÅŸÃ¼k-orta seviye Ã¶zelliklerdir.
>
> **Discriminative Fine-Tuning** stratejimiz:
>
> - Feature Extractor katmanlarÄ±: DÃ¼ÅŸÃ¼k learning rate (2e-4) â†’ Ã–ÄŸrenilmiÅŸ Ã¶zellikleri korur
> - Classifier katmanÄ±: YÃ¼ksek learning rate (2e-3) â†’ Yeni gÃ¶reve hÄ±zla adapte olur
>
> Bu sayede hem pretrained bilgiyi korur hem de yeni gÃ¶reve uyum saÄŸlarÄ±z."

---

### ğŸ“Œ Slide 3.4: Bizim Model KonfigÃ¼rasyonu

#### Slide Ä°Ã§eriÄŸi:

- BaÅŸlÄ±k: "Retinal Disease Classifier: Model Ã–zeti"
- Model akÄ±ÅŸ diyagramÄ± (Input â†’ ConvNeXt â†’ Classifier â†’ Sigmoid â†’ 43 Output)
- Parametre Ã¶zet tablosu

#### GÃ¶rseller:

- End-to-end model pipeline gÃ¶rseli
- Multi-label output aÃ§Ä±klama gÃ¶rseli (43 baÄŸÄ±msÄ±z sigmoid)

#### Tablo (Slide'a eklenecek):

| Parametre            | DeÄŸer               |
| -------------------- | ------------------- |
| Backbone             | ConvNeXt-Tiny       |
| Pretrained Weights   | ImageNet-1K         |
| Input Size           | 224 Ã— 224 Ã— 3       |
| Feature Dimension    | 768                 |
| Output Classes       | 43                  |
| Total Parameters     | ~28.6 milyon        |
| Trainable Parameters | ~28.6 milyon        |
| Output Activation    | Sigmoid (per-class) |

#### AnlatÄ±m Metni:

> "Åimdi bizim model konfigÃ¼rasyonumuzu Ã¶zetleyelim.
>
> **GiriÅŸ**: 224Ã—224 piksel boyutunda RGB fundus gÃ¶rÃ¼ntÃ¼sÃ¼
>
> **Feature Extraction**: ConvNeXt-Tiny backbone, ImageNet pretrained aÄŸÄ±rlÄ±klarla baÅŸlatÄ±lÄ±r. 4 stage boyunca gÃ¶rÃ¼ntÃ¼yÃ¼ iÅŸler ve 7Ã—7Ã—768 boyutunda Ã¶zellik haritasÄ± Ã§Ä±karÄ±r.
>
> **Global Average Pooling**: Ã–zellik haritasÄ±nÄ± 768 boyutlu vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
>
> **Classifier**: 768â†’43 boyutlu fully connected layer. Orijinal 1000 sÄ±nÄ±flÄ± ImageNet classifier'Ä± bizim 43 hastalÄ±k sÄ±nÄ±fÄ±mÄ±z iÃ§in deÄŸiÅŸtirilmiÅŸtir.
>
> **Multi-label Output**: Her bir sÄ±nÄ±f iÃ§in baÄŸÄ±msÄ±z sigmoid aktivasyonu uygulanÄ±r. Bu sayede bir gÃ¶rÃ¼ntÃ¼de birden fazla hastalÄ±k aynÄ± anda tespit edilebilir. Ã–rneÄŸin, bir hasta hem diyabetik retinopati hem de makula dejenerasyonuna sahip olabilir.
>
> Threshold deÄŸeri 0.5'tir - sigmoid Ã§Ä±ktÄ±sÄ± 0.5'in Ã¼zerindeyse o hastalÄ±k 'var' olarak kabul edilir."

---

### ğŸ–¼ï¸ Model Mimarisi BÃ¶lÃ¼mÃ¼ iÃ§in HazÄ±rlanabilecek GÃ¶rseller Ã–zeti:

| GÃ¶rsel No | AÃ§Ä±klama                                  | Nereden Bulunabilir/NasÄ±l HazÄ±rlanÄ±r |
| --------- | ----------------------------------------- | ------------------------------------ |
| 1         | CNN geliÅŸim tarihi (AlexNetâ†’ConvNeXt)     | Ä°nternetten timeline gÃ¶rseli         |
| 2         | ConvNeXt Block DiyagramÄ±                  | Orijinal paper'dan (Figure 2)        |
| 3         | ConvNeXt vs ResNet vs ViT karÅŸÄ±laÅŸtÄ±rmasÄ± | Paper'dan accuracy tablosu           |
| 4         | Transfer Learning Konsept                 | Genel infografik                     |
| 5         | Feature Extractor + Classifier ayrÄ±mÄ±     | Ã–zel Ã§izim                           |
| 6         | Discriminative LR gÃ¶rseli                 | LR deÄŸerlerini gÃ¶steren bar chart    |
| 7         | End-to-end pipeline                       | Inputâ†’Modelâ†’Output akÄ±ÅŸ ÅŸemasÄ±       |
| 8         | Multi-label output aÃ§Ä±klama               | 43 sigmoid Ã§Ä±kÄ±ÅŸÄ± gÃ¶steren diyagram  |

---

### ğŸ“š Model Mimarisi - Kaynak Referanslar:

1. **ConvNeXt Paper**: Liu et al., "A ConvNet for the 2020s", CVPR 2022
   - https://arxiv.org/abs/2201.03545
2. **ImageNet**: Deng et al., "ImageNet: A Large-Scale Hierarchical Image Database", CVPR 2009
3. **Transfer Learning Survey**: Zhuang et al., "A Comprehensive Survey on Transfer Learning", 2020

---

## 4. Veri Ã–n Ä°ÅŸleme ve Augmentation

### SÃ¶ylenebilecekler:

- **Normalizasyon**: ImageNet istatistikleri kullanÄ±ldÄ± (mean, std)
- **Temel Augmentation**:
  - Resize (224x224)
  - Random Rotation (180Â°)
  - Horizontal/Vertical Flip (%50)
  - Sharpness Adjustment
  - Center Crop
- **GeliÅŸmiÅŸ Augmentation**:
  - **ColorJitter**: ParlaklÄ±k, kontrast, doygunluk, ton deÄŸiÅŸimleri
  - **RandomAffine**: DÃ¶ndÃ¼rme, Ã¶teleme, Ã¶lÃ§ekleme, eÄŸme
  - **GaussianBlur**: BulanÄ±klÄ±k efekti
  - **Random Erasing (Cutout)**: Rastgele bÃ¶lge silme - overfitting'e karÅŸÄ±

### Neden Bu Augmentation'lar?

- Retinal gÃ¶rÃ¼ntÃ¼ler farklÄ± aÃ§Ä±lardan Ã§ekilebilir â†’ Rotation gerekli
- AydÄ±nlatma koÅŸullarÄ± deÄŸiÅŸken â†’ ColorJitter gerekli
- KÃ¼Ã§Ã¼k veri seti â†’ Daha fazla augmentation = daha iyi genelleme

### GÃ¶sterilebilecek GÃ¶rseller:

- AynÄ± gÃ¶rÃ¼ntÃ¼nÃ¼n farklÄ± augmentation versiyonlarÄ±
- Augmentation Ã¶ncesi vs sonrasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 5. SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler

### SÃ¶ylenebilecekler:

- **Problem**: 43 sÄ±nÄ±f arasÄ±nda ciddi dengesizlik
  - En yaygÄ±n sÄ±nÄ±f: ~500 Ã¶rnek
  - En nadir sÄ±nÄ±f: <10 Ã¶rnek
- **Ã‡Ã¶zÃ¼mler**:

#### 1. Focal Loss

- Standart BCE loss'un geliÅŸtirilmiÅŸ versiyonu
- Kolay Ã¶rnekleri down-weight eder, zor Ã¶rneklere odaklanÄ±r
- FormÃ¼l: FL(p_t) = -Î±(1-p_t)^Î³ log(p_t)
- Î³ (gamma) = 2.0 kullanÄ±ldÄ±

#### 2. Weighted BCE Loss

- Pozitif sÄ±nÄ±flara daha yÃ¼ksek aÄŸÄ±rlÄ±k verilir
- pos_weight = (negatif Ã¶rnek sayÄ±sÄ±) / (pozitif Ã¶rnek sayÄ±sÄ±)

#### 3. Asymmetric Loss

- Pozitif ve negatif Ã¶rnekler iÃ§in farklÄ± gamma deÄŸerleri
- Negatif baskÄ±n veri setleri iÃ§in Ã¶zellikle etkili

#### 4. Weighted Random Sampler

- Her batch'te sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± dengelemek iÃ§in kullanÄ±lÄ±r

### GÃ¶sterilebilecek GÃ¶rseller:

- SÄ±nÄ±f frekansÄ± vs F1 score grafiÄŸi
- Orijinal vs iyileÅŸtirilmiÅŸ model F1 karÅŸÄ±laÅŸtÄ±rmasÄ±
- Focal Loss vs BCE Loss karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 6. EÄŸitim Stratejisi

### SÃ¶ylenebilecekler:

#### Optimizer: AdamW

- Adam + Weight Decay (L2 regularization)
- Weight Decay: 1e-4

#### Learning Rate Stratejisi:

- **LR Finder** kullanÄ±larak optimal LR belirlendi
- **Discriminative Fine-tuning**:
  - Feature extractor: LR = 2e-4 (dÃ¼ÅŸÃ¼k)
  - Classifier: LR = 2e-3 (yÃ¼ksek)
  - Ã–nceden Ã¶ÄŸrenilmiÅŸ Ã¶zellikler korunur, classifier hÄ±zla adapte olur

#### Scheduler: Cosine Annealing

- Learning rate zamanla azalarak 1e-6'ya dÃ¼ÅŸer
- Daha yumuÅŸak optimizasyon

#### EÄŸitim AyarlarÄ±:

- Batch Size: 64
- Epoch SayÄ±sÄ±: 30
- Early Stopping Patience: 5
- Gradient Clipping: 1.0 (gradyan patlamasÄ±nÄ± Ã¶nler)

### GÃ¶sterilebilecek GÃ¶rseller:

- LR Finder grafiÄŸi
- Training vs Validation Loss/Accuracy eÄŸrileri
- Learning Rate schedule grafiÄŸi

---

## 7. SonuÃ§lar ve Performans

### SÃ¶ylenebilecekler:

#### Test Metrikleri:

| Metrik                      | DeÄŸer  |
| --------------------------- | ------ |
| Test Accuracy               | %98.5  |
| Test Loss                   | 0.0494 |
| Ã–ÄŸrenilen SÄ±nÄ±flar (F1 > 0) | 16/43  |
| En Ä°yi SÄ±nÄ±flar F1          | %70-80 |

#### DetaylÄ± Analiz:

- **Yeterli veri olan sÄ±nÄ±flar**: F1 score ~%70-80 baÅŸarÄ±
- **Nadir sÄ±nÄ±flar iki kategoriye ayrÄ±lÄ±yor**:
  1. Ä°yi Ã¶ÄŸrenilen ama dÃ¼ÅŸÃ¼k recall (precision > recall)
  2. HiÃ§ Ã¶ÄŸrenilemeyen sÄ±nÄ±flar (F1 = 0)
- **Multi-label Performans**: Birden fazla hastalÄ±ÄŸÄ± baÅŸarÄ±yla tespit edebiliyor

#### SÄ±nÄ±f BazlÄ± Metrikler:

- **Precision**: Model "hastalÄ±k var" dediÄŸinde ne kadar doÄŸru?
- **Recall**: GerÃ§ekte hastalÄ±k olanlarÄ±n ne kadarÄ± tespit edildi?
- **F1 Score**: Precision ve Recall'un harmonik ortalamasÄ±

### GÃ¶sterilebilecek GÃ¶rseller:

- Training/Validation loss ve accuracy eÄŸrileri
- SÄ±nÄ±f bazlÄ± Precision, Recall, F1 bar chart
- Confusion matrix (en yaygÄ±n 10 hastalÄ±k iÃ§in)
- Nadir sÄ±nÄ±flar iÃ§in confusion matrix grid
- ROC eÄŸrileri (seÃ§ili sÄ±nÄ±flar iÃ§in)
- Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi (Orijinal vs Ä°yileÅŸtirilmiÅŸ)

---

## 8. Demo ve Ã–rnek Tahminler

### SÃ¶ylenebilecekler:

- EÄŸitilmiÅŸ model ile yeni gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde tahmin yapÄ±labilir
- `inference.py` ile tek gÃ¶rÃ¼ntÃ¼ veya toplu tahmin desteÄŸi
- Threshold = 0.5 kullanÄ±larak multi-label tahminler

### Demo AkÄ±ÅŸÄ±:

1. Ã–rnek bir fundus gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kle
2. Model tahminlerini gÃ¶ster
3. OlasÄ±lÄ±k deÄŸerleri ile birlikte tespit edilen hastalÄ±klarÄ± listele

### KullanÄ±m:

```bash
# Tek gÃ¶rÃ¼ntÃ¼ tahmini
python inference.py --image ./test_image.png --model ./outputs/checkpoints/best_model.pth

# Toplu tahmin
python inference.py --folder ./test_images/ --output predictions.csv
```

### GÃ¶sterilebilecek GÃ¶rseller:

- Ã–rnek tahmin sonuÃ§larÄ± (gÃ¶rÃ¼ntÃ¼ + tespit edilen hastalÄ±klar)
- OlasÄ±lÄ±k Ã§Ä±ktÄ±larÄ± ile birlikte Ã¶rnek tahminler

---

## 9. SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar

### SÃ¶ylenebilecekler:

#### BaÅŸarÄ±lar:

- âœ… 43 sÄ±nÄ±flÄ± multi-label classification baÅŸarÄ±yla gerÃ§ekleÅŸtirildi
- âœ… Transfer learning ile sÄ±nÄ±rlÄ± veriyle yÃ¼ksek performans
- âœ… Focal Loss ile sÄ±nÄ±f dengesizliÄŸi kÄ±smen aÅŸÄ±ldÄ±
- âœ… %98.5 test accuracy elde edildi
- âœ… ModÃ¼ler, yeniden kullanÄ±labilir kod yapÄ±sÄ±

#### Limitasyonlar:

- âš ï¸ Nadir sÄ±nÄ±flarda dÃ¼ÅŸÃ¼k recall
- âš ï¸ BazÄ± Ã§ok nadir hastalÄ±klar (< 10 Ã¶rnek) Ã¶ÄŸrenilemiyor
- âš ï¸ Daha fazla veri ile performans artÄ±rÄ±labilir

#### Gelecek Ã‡alÄ±ÅŸmalar:

- ğŸ“ˆ Veri artÄ±rma: Daha fazla etiketli veri toplama
- ğŸ“ˆ Class-aware sampling stratejileri
- ğŸ“ˆ Knowledge distillation
- ğŸ“ˆ Ensemble modeller
- ğŸ“ˆ Explainability: Grad-CAM ile hastalÄ±k bÃ¶lgelerini gÃ¶rselleÅŸtirme
- ğŸ“ˆ Ã‡apraz doÄŸrulama (Cross-validation)
- ğŸ“ˆ Daha bÃ¼yÃ¼k ConvNeXt modelleri (Small, Base)

### GÃ¶sterilebilecek GÃ¶rseller:

- Proje Ã¶zet tablosu
- Gelecek Ã§alÄ±ÅŸmalar iÃ§in yol haritasÄ±

---

## ğŸ“Š Notebookta Mevcut Ã–nemli GÃ¶rseller

| GÃ¶rsel Tipi          | AÃ§Ä±klama                         | Notebook HÃ¼cresi |
| -------------------- | -------------------------------- | ---------------- |
| SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±       | HastalÄ±k baÅŸÄ±na Ã¶rnek sayÄ±sÄ±     | Cell #12-13      |
| Ã–rnek GÃ¶rÃ¼ntÃ¼ler     | 0-5 hastalÄ±k iÃ§eren fundus       | Cell #14-17      |
| Training Curves      | Loss ve Accuracy grafikleri      | Cell #78         |
| F1 KarÅŸÄ±laÅŸtÄ±rmasÄ±   | Orijinal vs Ä°yileÅŸtirilmiÅŸ model | Cell #50         |
| Confusion Matrix     | Top-10 sÄ±nÄ±flar iÃ§in             | Cell #80         |
| Nadir SÄ±nÄ±f CM       | En az Ã¶rneÄŸi olan 10 sÄ±nÄ±f       | Cell #52         |
| SÄ±nÄ±f FrekansÄ± vs F1 | Ä°yileÅŸme analizi                 | Cell #50         |
| Metrik Bar Chart     | Precision, Recall, F1            | Cell #75         |

---

## ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±

| Kategori       | Teknoloji                                 |
| -------------- | ----------------------------------------- |
| Framework      | PyTorch                                   |
| Model          | ConvNeXt-Tiny (ImageNet pretrained)       |
| Loss Functions | Focal Loss, Weighted BCE, Asymmetric Loss |
| Optimizer      | AdamW + Discriminative LR                 |
| Scheduler      | Cosine Annealing                          |
| Ortam          | Google Colab (GPU) / Local                |
| Veri Ä°ÅŸleme    | torchvision transforms                    |
| GÃ¶rselleÅŸtirme | matplotlib, seaborn                       |
| Metrikler      | sklearn, custom metrics                   |

---

## ğŸ“š Kaynaklar

1. **RFMiD Dataset**: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification
2. **ConvNeXt Paper**: Liu et al., "A ConvNet for the 2020s", CVPR 2022
3. **Focal Loss Paper**: Lin et al., "Focal Loss for Dense Object Detection", ICCV 2017
4. **Asymmetric Loss Paper**: Ridnik et al., "Asymmetric Loss For Multi-Label Classification", ICCV 2021
