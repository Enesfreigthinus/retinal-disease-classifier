# Retinal Disease Classifier - Sunum TaslaÄŸÄ±

## ğŸ“‹ Ä°Ã§indekiler

1. [GiriÅŸ ve Problem TanÄ±mÄ±](#1-giriÅŸ-ve-problem-tanÄ±mÄ±)
2. [Veri Seti](#2-veri-seti)
3. [Model Mimarisi](#3-model-mimarisi)
4. [Veri Ã–n Ä°ÅŸleme ve Augmentation](#4-veri-Ã¶n-iÅŸleme-ve-augmentation)
5. [SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler](#5-sÄ±nÄ±f-dengesizliÄŸi-ve-Ã§Ã¶zÃ¼mler)
6. [EÄŸitim Stratejisi](#6-eÄŸitim-stratejisi)
7. [SonuÃ§lar ve Performans](#7-sonuÃ§lar-ve-performans)
8. [Demo ve Ã–rnek Tahminler](#8-demo-ve-Ã¶rnek-tahminler)
9. [SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar](#9-sonuÃ§-ve-gelecek-Ã§alÄ±ÅŸmalar)

---

## 1. GiriÅŸ ve Problem TanÄ±mÄ±

### SÃ¶ylenebilecekler:

- **Problem**: Retinal (gÃ¶z dibi) gÃ¶rÃ¼ntÃ¼lerinden hastalÄ±k tespiti, oftalmologlar iÃ§in zaman alÄ±cÄ± ve uzmanlÄ±k gerektiren bir sÃ¼reÃ§tir.
- **Motivasyon**: Diyabetik retinopati, yaÅŸa baÄŸlÄ± makula dejenerasyonu gibi hastalÄ±klarÄ±n erken tespiti kÃ¶rlÃ¼ÄŸÃ¼ Ã¶nleyebilir.
- **AmaÃ§**: Fundus gÃ¶rÃ¼ntÃ¼lerinden otomatik olarak **43 farklÄ± retinal hastalÄ±ÄŸÄ±** tespit edebilen bir derin Ã¶ÄŸrenme modeli geliÅŸtirmek.
- **Multi-label Classification**: Tek bir gÃ¶rÃ¼ntÃ¼de birden fazla hastalÄ±k aynÄ± anda bulunabilir (Ã¶rn: hem diyabetik retinopati hem makula dejenerasyonu).
- **Klinik Ã–nemi**: Yapay zeka destekli tanÄ± sistemleri, Ã¶zellikle uzman hekim eriÅŸiminin kÄ±sÄ±tlÄ± olduÄŸu bÃ¶lgelerde hayat kurtarÄ±cÄ± olabilir.

### GÃ¶sterilebilecek GÃ¶rseller:

- Normal vs hastalÄ±klÄ± retina gÃ¶rÃ¼ntÃ¼sÃ¼ karÅŸÄ±laÅŸtÄ±rmasÄ± (notebook'ta mevcut)
- 0'dan 5'e kadar hastalÄ±k iÃ§eren Ã¶rnek fundus gÃ¶rÃ¼ntÃ¼leri

---

## 2. Veri Seti

### SÃ¶ylenebilecekler:

- **Kaynak**: RFMiD (Retinal Fundus Multi-disease Image Dataset) - Kaggle
- **Toplam GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±**: 3200 fundus gÃ¶rÃ¼ntÃ¼sÃ¼
  - EÄŸitim: 1920 gÃ¶rÃ¼ntÃ¼
  - DoÄŸrulama: 640 gÃ¶rÃ¼ntÃ¼
  - Test: 640 gÃ¶rÃ¼ntÃ¼
- **SÄ±nÄ±f SayÄ±sÄ±**: 43 farklÄ± retinal hastalÄ±k (HR ve ODPM hariÃ§ tutulmuÅŸtur)
- **GÃ¶rÃ¼ntÃ¼ Boyutu**: 224x224 piksel (yeniden boyutlandÄ±rÄ±lmÄ±ÅŸ)

### Tespit Edilen HastalÄ±klar:

- Diyabetik Retinopati (DR)
- YaÅŸa BaÄŸlÄ± Makula Dejenerasyonu (ARMD)
- Makula DeliÄŸi (MH)
- Diyabetik Nefropati (DN)
- Miyopi (MYA)
- Retinal Ven TÄ±kanÄ±klÄ±ÄŸÄ± (BRVO)
- Ve 37 ek hastalÄ±k daha...

### Veri Seti ZorluklarÄ±:

- **Ciddi SÄ±nÄ±f DengesizliÄŸi**: BazÄ± hastalÄ±klar Ã§ok nadir (10'dan az Ã¶rnek), bazÄ±larÄ± yaygÄ±n (500+ Ã¶rnek)
- **Multi-label YapÄ±**: Bir gÃ¶rÃ¼ntÃ¼de 0-5+ hastalÄ±k bulunabilir

### GÃ¶sterilebilecek GÃ¶rseller:

- HastalÄ±k baÅŸÄ±na Ã¶rnek sayÄ±sÄ±nÄ± gÃ¶steren bar chart (sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±)
- GÃ¶rÃ¼ntÃ¼ baÅŸÄ±na hastalÄ±k sayÄ±sÄ± histogramÄ±
- FarklÄ± sayÄ±da hastalÄ±k iÃ§eren Ã¶rnek fundus gÃ¶rÃ¼ntÃ¼leri (0-5 hastalÄ±k)

---

## 3. Model Mimarisi

### SÃ¶ylenebilecekler:

- **Backbone**: ConvNeXt-Tiny
  - 2022'de Facebook tarafÄ±ndan geliÅŸtirilen modern CNN mimarisi
  - ImageNet Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar (transfer learning)
  - ResNet'in tasarÄ±m prensiplerini Vision Transformer'larla modernize ediyor
- **Transfer Learning AvantajlarÄ±**:
  - DÃ¼ÅŸÃ¼k veri miktarÄ±yla yÃ¼ksek performans
  - Genel gÃ¶rsel Ã¶zellikler zaten Ã¶ÄŸrenilmiÅŸ
  - Daha hÄ±zlÄ± yakÄ±nsama
- **Classifier KatmanÄ±**: Son katman 43 Ã§Ä±kÄ±ÅŸlÄ± linear layer ile deÄŸiÅŸtirildi
- **Multi-label Ã‡Ä±kÄ±ÅŸ**: Her sÄ±nÄ±f iÃ§in baÄŸÄ±msÄ±z sigmoid aktivasyonu

### Model Parametreleri:

- Toplam parametre: ~28 milyon
- EÄŸitilebilir parametre: TÃ¼m aÄŸ (discriminative learning rate ile)

### Desteklenen Alternatif Modeller (ModelFactory):

- ConvNeXt-Small, ConvNeXt-Base
- ResNet50, ResNet101
- EfficientNet-B0, EfficientNet-B3

### GÃ¶sterilebilecek GÃ¶rseller:

- ConvNeXt mimarisi ÅŸemasÄ±
- Model Ã¶zet tablosu (parametre sayÄ±larÄ±)

---

## 4. Veri Ã–n Ä°ÅŸleme ve Augmentation

### SÃ¶ylenebilecekler:

- **Normalizasyon**: ImageNet istatistikleri kullanÄ±ldÄ± (mean, std)
- **Temel Augmentation**:
  - Resize (224x224)
  - Random Rotation (180Â°)
  - Horizontal/Vertical Flip (%50)
  - Sharpness Adjustment
  - Center Crop
- **GeliÅŸmiÅŸ Augmentation**:
  - **ColorJitter**: ParlaklÄ±k, kontrast, doygunluk, ton deÄŸiÅŸimleri
  - **RandomAffine**: DÃ¶ndÃ¼rme, Ã¶teleme, Ã¶lÃ§ekleme, eÄŸme
  - **GaussianBlur**: BulanÄ±klÄ±k efekti
  - **Random Erasing (Cutout)**: Rastgele bÃ¶lge silme - overfitting'e karÅŸÄ±

### Neden Bu Augmentation'lar?

- Retinal gÃ¶rÃ¼ntÃ¼ler farklÄ± aÃ§Ä±lardan Ã§ekilebilir â†’ Rotation gerekli
- AydÄ±nlatma koÅŸullarÄ± deÄŸiÅŸken â†’ ColorJitter gerekli
- KÃ¼Ã§Ã¼k veri seti â†’ Daha fazla augmentation = daha iyi genelleme

### GÃ¶sterilebilecek GÃ¶rseller:

- AynÄ± gÃ¶rÃ¼ntÃ¼nÃ¼n farklÄ± augmentation versiyonlarÄ±
- Augmentation Ã¶ncesi vs sonrasÄ± karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 5. SÄ±nÄ±f DengesizliÄŸi ve Ã‡Ã¶zÃ¼mler

### SÃ¶ylenebilecekler:

- **Problem**: 43 sÄ±nÄ±f arasÄ±nda ciddi dengesizlik
  - En yaygÄ±n sÄ±nÄ±f: ~500 Ã¶rnek
  - En nadir sÄ±nÄ±f: <10 Ã¶rnek
- **Ã‡Ã¶zÃ¼mler**:

#### 1. Focal Loss

- Standart BCE loss'un geliÅŸtirilmiÅŸ versiyonu
- Kolay Ã¶rnekleri down-weight eder, zor Ã¶rneklere odaklanÄ±r
- FormÃ¼l: FL(p_t) = -Î±(1-p_t)^Î³ log(p_t)
- Î³ (gamma) = 2.0 kullanÄ±ldÄ±

#### 2. Weighted BCE Loss

- Pozitif sÄ±nÄ±flara daha yÃ¼ksek aÄŸÄ±rlÄ±k verilir
- pos_weight = (negatif Ã¶rnek sayÄ±sÄ±) / (pozitif Ã¶rnek sayÄ±sÄ±)

#### 3. Asymmetric Loss

- Pozitif ve negatif Ã¶rnekler iÃ§in farklÄ± gamma deÄŸerleri
- Negatif baskÄ±n veri setleri iÃ§in Ã¶zellikle etkili

#### 4. Weighted Random Sampler

- Her batch'te sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± dengelemek iÃ§in kullanÄ±lÄ±r

### GÃ¶sterilebilecek GÃ¶rseller:

- SÄ±nÄ±f frekansÄ± vs F1 score grafiÄŸi
- Orijinal vs iyileÅŸtirilmiÅŸ model F1 karÅŸÄ±laÅŸtÄ±rmasÄ±
- Focal Loss vs BCE Loss karÅŸÄ±laÅŸtÄ±rmasÄ±

---

## 6. EÄŸitim Stratejisi

### SÃ¶ylenebilecekler:

#### Optimizer: AdamW

- Adam + Weight Decay (L2 regularization)
- Weight Decay: 1e-4

#### Learning Rate Stratejisi:

- **LR Finder** kullanÄ±larak optimal LR belirlendi
- **Discriminative Fine-tuning**:
  - Feature extractor: LR = 2e-4 (dÃ¼ÅŸÃ¼k)
  - Classifier: LR = 2e-3 (yÃ¼ksek)
  - Ã–nceden Ã¶ÄŸrenilmiÅŸ Ã¶zellikler korunur, classifier hÄ±zla adapte olur

#### Scheduler: Cosine Annealing

- Learning rate zamanla azalarak 1e-6'ya dÃ¼ÅŸer
- Daha yumuÅŸak optimizasyon

#### EÄŸitim AyarlarÄ±:

- Batch Size: 64
- Epoch SayÄ±sÄ±: 30
- Early Stopping Patience: 5
- Gradient Clipping: 1.0 (gradyan patlamasÄ±nÄ± Ã¶nler)

### GÃ¶sterilebilecek GÃ¶rseller:

- LR Finder grafiÄŸi
- Training vs Validation Loss/Accuracy eÄŸrileri
- Learning Rate schedule grafiÄŸi

---

## 7. SonuÃ§lar ve Performans

### SÃ¶ylenebilecekler:

#### Test Metrikleri:

| Metrik                      | DeÄŸer  |
| --------------------------- | ------ |
| Test Accuracy               | %98.5  |
| Test Loss                   | 0.0494 |
| Ã–ÄŸrenilen SÄ±nÄ±flar (F1 > 0) | 16/43  |
| En Ä°yi SÄ±nÄ±flar F1          | %70-80 |

#### DetaylÄ± Analiz:

- **Yeterli veri olan sÄ±nÄ±flar**: F1 score ~%70-80 baÅŸarÄ±
- **Nadir sÄ±nÄ±flar iki kategoriye ayrÄ±lÄ±yor**:
  1. Ä°yi Ã¶ÄŸrenilen ama dÃ¼ÅŸÃ¼k recall (precision > recall)
  2. HiÃ§ Ã¶ÄŸrenilemeyen sÄ±nÄ±flar (F1 = 0)
- **Multi-label Performans**: Birden fazla hastalÄ±ÄŸÄ± baÅŸarÄ±yla tespit edebiliyor

#### SÄ±nÄ±f BazlÄ± Metrikler:

- **Precision**: Model "hastalÄ±k var" dediÄŸinde ne kadar doÄŸru?
- **Recall**: GerÃ§ekte hastalÄ±k olanlarÄ±n ne kadarÄ± tespit edildi?
- **F1 Score**: Precision ve Recall'un harmonik ortalamasÄ±

### GÃ¶sterilebilecek GÃ¶rseller:

- Training/Validation loss ve accuracy eÄŸrileri
- SÄ±nÄ±f bazlÄ± Precision, Recall, F1 bar chart
- Confusion matrix (en yaygÄ±n 10 hastalÄ±k iÃ§in)
- Nadir sÄ±nÄ±flar iÃ§in confusion matrix grid
- ROC eÄŸrileri (seÃ§ili sÄ±nÄ±flar iÃ§in)
- Model karÅŸÄ±laÅŸtÄ±rma grafiÄŸi (Orijinal vs Ä°yileÅŸtirilmiÅŸ)

---

## 8. Demo ve Ã–rnek Tahminler

### SÃ¶ylenebilecekler:

- EÄŸitilmiÅŸ model ile yeni gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde tahmin yapÄ±labilir
- `inference.py` ile tek gÃ¶rÃ¼ntÃ¼ veya toplu tahmin desteÄŸi
- Threshold = 0.5 kullanÄ±larak multi-label tahminler

### Demo AkÄ±ÅŸÄ±:

1. Ã–rnek bir fundus gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kle
2. Model tahminlerini gÃ¶ster
3. OlasÄ±lÄ±k deÄŸerleri ile birlikte tespit edilen hastalÄ±klarÄ± listele

### KullanÄ±m:

```bash
# Tek gÃ¶rÃ¼ntÃ¼ tahmini
python inference.py --image ./test_image.png --model ./outputs/checkpoints/best_model.pth

# Toplu tahmin
python inference.py --folder ./test_images/ --output predictions.csv
```

### GÃ¶sterilebilecek GÃ¶rseller:

- Ã–rnek tahmin sonuÃ§larÄ± (gÃ¶rÃ¼ntÃ¼ + tespit edilen hastalÄ±klar)
- OlasÄ±lÄ±k Ã§Ä±ktÄ±larÄ± ile birlikte Ã¶rnek tahminler

---

## 9. SonuÃ§ ve Gelecek Ã‡alÄ±ÅŸmalar

### SÃ¶ylenebilecekler:

#### BaÅŸarÄ±lar:

- âœ… 43 sÄ±nÄ±flÄ± multi-label classification baÅŸarÄ±yla gerÃ§ekleÅŸtirildi
- âœ… Transfer learning ile sÄ±nÄ±rlÄ± veriyle yÃ¼ksek performans
- âœ… Focal Loss ile sÄ±nÄ±f dengesizliÄŸi kÄ±smen aÅŸÄ±ldÄ±
- âœ… %98.5 test accuracy elde edildi
- âœ… ModÃ¼ler, yeniden kullanÄ±labilir kod yapÄ±sÄ±

#### Limitasyonlar:

- âš ï¸ Nadir sÄ±nÄ±flarda dÃ¼ÅŸÃ¼k recall
- âš ï¸ BazÄ± Ã§ok nadir hastalÄ±klar (< 10 Ã¶rnek) Ã¶ÄŸrenilemiyor
- âš ï¸ Daha fazla veri ile performans artÄ±rÄ±labilir

#### Gelecek Ã‡alÄ±ÅŸmalar:

- ğŸ“ˆ Veri artÄ±rma: Daha fazla etiketli veri toplama
- ğŸ“ˆ Class-aware sampling stratejileri
- ğŸ“ˆ Knowledge distillation
- ğŸ“ˆ Ensemble modeller
- ğŸ“ˆ Explainability: Grad-CAM ile hastalÄ±k bÃ¶lgelerini gÃ¶rselleÅŸtirme
- ğŸ“ˆ Ã‡apraz doÄŸrulama (Cross-validation)
- ğŸ“ˆ Daha bÃ¼yÃ¼k ConvNeXt modelleri (Small, Base)

### GÃ¶sterilebilecek GÃ¶rseller:

- Proje Ã¶zet tablosu
- Gelecek Ã§alÄ±ÅŸmalar iÃ§in yol haritasÄ±

---

## ğŸ“Š Notebookta Mevcut Ã–nemli GÃ¶rseller

| GÃ¶rsel Tipi          | AÃ§Ä±klama                         | Notebook HÃ¼cresi |
| -------------------- | -------------------------------- | ---------------- |
| SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±       | HastalÄ±k baÅŸÄ±na Ã¶rnek sayÄ±sÄ±     | Cell #12-13      |
| Ã–rnek GÃ¶rÃ¼ntÃ¼ler     | 0-5 hastalÄ±k iÃ§eren fundus       | Cell #14-17      |
| Training Curves      | Loss ve Accuracy grafikleri      | Cell #78         |
| F1 KarÅŸÄ±laÅŸtÄ±rmasÄ±   | Orijinal vs Ä°yileÅŸtirilmiÅŸ model | Cell #50         |
| Confusion Matrix     | Top-10 sÄ±nÄ±flar iÃ§in             | Cell #80         |
| Nadir SÄ±nÄ±f CM       | En az Ã¶rneÄŸi olan 10 sÄ±nÄ±f       | Cell #52         |
| SÄ±nÄ±f FrekansÄ± vs F1 | Ä°yileÅŸme analizi                 | Cell #50         |
| Metrik Bar Chart     | Precision, Recall, F1            | Cell #75         |

---

## ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±

| Kategori       | Teknoloji                                 |
| -------------- | ----------------------------------------- |
| Framework      | PyTorch                                   |
| Model          | ConvNeXt-Tiny (ImageNet pretrained)       |
| Loss Functions | Focal Loss, Weighted BCE, Asymmetric Loss |
| Optimizer      | AdamW + Discriminative LR                 |
| Scheduler      | Cosine Annealing                          |
| Ortam          | Google Colab (GPU) / Local                |
| Veri Ä°ÅŸleme    | torchvision transforms                    |
| GÃ¶rselleÅŸtirme | matplotlib, seaborn                       |
| Metrikler      | sklearn, custom metrics                   |

---

## ğŸ“š Kaynaklar

1. **RFMiD Dataset**: https://www.kaggle.com/datasets/andrewmvd/retinal-disease-classification
2. **ConvNeXt Paper**: Liu et al., "A ConvNet for the 2020s", CVPR 2022
3. **Focal Loss Paper**: Lin et al., "Focal Loss for Dense Object Detection", ICCV 2017
4. **Asymmetric Loss Paper**: Ridnik et al., "Asymmetric Loss For Multi-Label Classification", ICCV 2021
